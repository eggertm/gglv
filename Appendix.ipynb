{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.display.float_format = '{:,.3f}'.format\n",
    "\n",
    "# %matplotlib notebook\n",
    "import seaborn as sns\n",
    "sns.set(style=\"ticks\", color_codes=True)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.decomposition import PCA, NMF\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import BaggingRegressor, ExtraTreesRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "class Data:\n",
    "    #storage class for data\n",
    "    def __init__(self, filename, subset_count=None):\n",
    "        x = pd.read_csv(filename, index_col='id')\n",
    "        if subset_count is not None: # Nice to use for testing\n",
    "            permut = np.random.permutation(x.shape[0])[:subset_count]\n",
    "            x = x.iloc[permut, :]\n",
    "        \n",
    "        self.df_y = x['loss']\n",
    "        y = x['loss'].values\n",
    "        del x['loss']\n",
    "\n",
    "        convertedX = pd.get_dummies(x, drop_first=True)\n",
    "        X = convertedX.values\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        \n",
    "        self.df_X = convertedX\n",
    "        self.df_X_test = None\n",
    "    \n",
    "    def get_split(self, test_size=0.20, pca_components=None, nmf_components=None):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(self.X, self.y,\n",
    "                                                            test_size=test_size)\n",
    "        if pca_components is not None:\n",
    "            pca = PCA(n_components=pca_components)\n",
    "            pca.fit(X_train)\n",
    "            X_train = pca.transform(X_train)\n",
    "            X_test = pca.transform(X_test)\n",
    "        elif nmf_components:\n",
    "            nmf = NMF(n_components=nmf_components)\n",
    "            X_train = nmf.fit_transform(X_train)\n",
    "            X_test = nmf.transform(X_test)\n",
    "        return  X_train, X_test, y_train, y_test\n",
    "    \n",
    "    def remove_columns(self, columns):\n",
    "        columns = tuple(columns)\n",
    "        for col in self.df_X.columns:\n",
    "            if col.startswith(columns):\n",
    "                del self.df_X[col]\n",
    "        self.X = self.df_X.values\n",
    "    \n",
    "    def read_test_data(self, filename):\n",
    "        X_test = pd.read_csv(filename, index_col='id')\n",
    "        X_test = pd.get_dummies(X_test, drop_first=True)\n",
    "\n",
    "        additional_columns = set(X_test.columns) - set(self.df_X.columns)\n",
    "        X_test = X_test.drop(columns=additional_columns)\n",
    "\n",
    "        missing_columns = set(self.df_X.columns) - set(X_test.columns)\n",
    "        for col in missing_columns:\n",
    "            X_test[col] = 0\n",
    "            \n",
    "        self.df_X_test = X_test\n",
    "        return X_test.values\n",
    "    \n",
    "def evaluate(name, estimator, X_train, X_test, y_train, y_test):\n",
    "    t_0 = time.time()\n",
    "    print(f'{name}:')\n",
    "    estimator.fit(X_train, y_train)\n",
    "    \n",
    "    t_1 = time.time()\n",
    "    print(f'\\tTime elapsed for model construction {t_1 - t_0:.3f} sec')\n",
    "    y_test_predict = estimator.predict(X_test)\n",
    "    error_test = mean_absolute_error(y_test, y_test_predict)\n",
    "    error_train = mean_absolute_error(y_train, estimator.predict(X_train))\n",
    "    print(f'\\tTime elapsed for prediction {time.time() - t_1:.3f} sec')\n",
    "    print(f'\\tTest error: {error_test:.3f}')\n",
    "    print(f'\\tTrain error: {error_train:.3f}')\n",
    "    return error_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression:\n",
      "\tTime elapsed for model construction 23.044 sec\n",
      "\tTime elapsed for prediction 0.478 sec\n",
      "\tTest error: 8798305800.629\n",
      "\tTrain error: 1480.444\n",
      "Ridge:\n",
      "\tTime elapsed for model construction 5.009 sec\n",
      "\tTime elapsed for prediction 0.391 sec\n",
      "\tTest error: 1477.830\n",
      "\tTrain error: 1481.719\n",
      "Lasso:\n",
      "\tTime elapsed for model construction 55.786 sec\n",
      "\tTime elapsed for prediction 0.389 sec\n",
      "\tTest error: 1481.435\n",
      "\tTrain error: 1493.583\n",
      "ElasticNet:\n",
      "\tTime elapsed for model construction 6.423 sec\n",
      "\tTime elapsed for prediction 0.389 sec\n",
      "\tTest error: 1745.976\n",
      "\tTrain error: 1764.948\n",
      "BaggingRegressor:\n",
      "\tTime elapsed for model construction 136.550 sec\n",
      "\tTime elapsed for prediction 34.328 sec\n",
      "\tTest error: 1519.984\n",
      "\tTrain error: 605.857\n",
      "ExtraTreesRegressor:\n",
      "\tTime elapsed for model construction 279.494 sec\n",
      "\tTime elapsed for prediction 1.537 sec\n",
      "\tTest error: 1535.685\n",
      "\tTrain error: 0.072\n",
      "RandomForestRegressor:\n",
      "\tTime elapsed for model construction 139.742 sec\n",
      "\tTime elapsed for prediction 1.370 sec\n",
      "\tTest error: 1519.550\n",
      "\tTrain error: 602.167\n",
      "GradientBoostingRegressor:\n",
      "\tTime elapsed for model construction 822.191 sec\n",
      "\tTime elapsed for prediction 1.641 sec\n",
      "\tTest error: 1444.904\n",
      "\tTrain error: 1453.168\n",
      "MLP:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Notandi\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTime elapsed for model construction 2397.275 sec\n",
      "\tTime elapsed for prediction 2.283 sec\n",
      "\tTest error: 1410.916\n",
      "\tTrain error: 1392.052\n",
      "KNeighborsRegressor:\n",
      "\tTime elapsed for model construction 119.529 sec\n",
      "\tTime elapsed for prediction 17134.402 sec\n",
      "\tTest error: 1672.010\n",
      "\tTrain error: 1364.940\n",
      "SVR:\n"
     ]
    }
   ],
   "source": [
    "# First overall test\n",
    "data = Data(\"train.csv\")\n",
    "data.remove_columns(['cont9', 'cont12', 'cat2', 'cat3', 'cat4', 'cat5', 'cat6', 'cat7', 'cat8', 'cat86'])\n",
    "X_train, X_test, y_train, y_test = data.get_split()\n",
    "\n",
    "ESTIMATORS = {\n",
    "    # Linear\n",
    "    \"LinearRegression\": LinearRegression(n_jobs=-1),\n",
    "    \"Ridge\": Ridge(),\n",
    "    \"Lasso\": Lasso(),\n",
    "    \"ElasticNet\": ElasticNet(),\n",
    "    # Non-linear\n",
    "    \"BaggingRegressor\": BaggingRegressor(n_jobs=-1),\n",
    "    \"ExtraTreesRegressor\": ExtraTreesRegressor(n_jobs=-1),\n",
    "    \"RandomForestRegressor\": RandomForestRegressor(n_jobs=-1),\n",
    "    \"GradientBoostingRegressor\": GradientBoostingRegressor(loss='huber'),\n",
    "    \"MLP\":  MLPRegressor(hidden_layer_sizes=(150,)),\n",
    "    \"KNeighborsRegressor\": KNeighborsRegressor(n_jobs=-1),\n",
    "    \"SVR\": SVR(),\n",
    "}\n",
    "\n",
    "for name, estimator in ESTIMATORS.items():\n",
    "    evaluate(name, estimator, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA with 120 components\n",
      "LinearRegression:\n",
      "\tTime elapsed for model construction 1.222 sec\n",
      "\tTime elapsed for prediction 0.052 sec\n",
      "\tTest error: 1336.491\n",
      "\tTrain error: 1326.450\n",
      "Ridge:\n",
      "\tTime elapsed for model construction 0.375 sec\n",
      "\tTime elapsed for prediction 0.047 sec\n",
      "\tTest error: 1336.488\n",
      "\tTrain error: 1326.447\n",
      "Lasso:\n",
      "\tTime elapsed for model construction 0.735 sec\n",
      "\tTime elapsed for prediction 0.050 sec\n",
      "\tTest error: 1335.520\n",
      "\tTrain error: 1325.040\n",
      "ElasticNet:\n",
      "\tTime elapsed for model construction 0.688 sec\n",
      "\tTime elapsed for prediction 0.059 sec\n",
      "\tTest error: 1503.928\n",
      "\tTrain error: 1487.781\n",
      "BaggingRegressor:\n",
      "\tTime elapsed for model construction 159.103 sec\n",
      "\tTime elapsed for prediction 7.503 sec\n",
      "\tTest error: 1385.234\n",
      "\tTrain error: 551.043\n",
      "ExtraTreesRegressor:\n",
      "\tTime elapsed for model construction 37.692 sec\n",
      "\tTime elapsed for prediction 0.782 sec\n",
      "\tTest error: 1379.454\n",
      "\tTrain error: 0.001\n",
      "RandomForestRegressor:\n",
      "\tTime elapsed for model construction 151.161 sec\n",
      "\tTime elapsed for prediction 0.754 sec\n",
      "\tTest error: 1390.771\n",
      "\tTrain error: 552.164\n",
      "GradientBoostingRegressor:\n",
      "\tTime elapsed for model construction 333.502 sec\n",
      "\tTime elapsed for prediction 0.793 sec\n",
      "\tTest error: 1317.153\n",
      "\tTrain error: 1290.940\n",
      "MLP:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Notandi\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTime elapsed for model construction 327.754 sec\n",
      "\tTime elapsed for prediction 1.168 sec\n",
      "\tTest error: 1224.814\n",
      "\tTrain error: 1195.139\n",
      "NMF with 90 components\n",
      "LinearRegression:\n",
      "\tTime elapsed for model construction 0.858 sec\n",
      "\tTime elapsed for prediction 0.047 sec\n",
      "\tTest error: 1372.249\n",
      "\tTrain error: 1369.867\n",
      "Ridge:\n",
      "\tTime elapsed for model construction 0.288 sec\n",
      "\tTime elapsed for prediction 0.031 sec\n",
      "\tTest error: 1367.990\n",
      "\tTrain error: 1366.349\n",
      "Lasso:\n",
      "\tTime elapsed for model construction 1.047 sec\n",
      "\tTime elapsed for prediction 0.047 sec\n",
      "\tTest error: 1380.740\n",
      "\tTrain error: 1380.795\n",
      "ElasticNet:\n",
      "\tTime elapsed for model construction 0.509 sec\n",
      "\tTime elapsed for prediction 0.047 sec\n",
      "\tTest error: 1969.046\n",
      "\tTrain error: 1961.323\n",
      "BaggingRegressor:\n",
      "\tTime elapsed for model construction 63.872 sec\n",
      "\tTime elapsed for prediction 6.347 sec\n",
      "\tTest error: 1350.245\n",
      "\tTrain error: 536.754\n",
      "ExtraTreesRegressor:\n",
      "\tTime elapsed for model construction 28.637 sec\n",
      "\tTime elapsed for prediction 0.648 sec\n",
      "\tTest error: 1359.542\n",
      "\tTrain error: 0.009\n",
      "RandomForestRegressor:\n",
      "\tTime elapsed for model construction 59.382 sec\n",
      "\tTime elapsed for prediction 0.608 sec\n",
      "\tTest error: 1344.332\n",
      "\tTrain error: 537.979\n",
      "GradientBoostingRegressor:\n",
      "\tTime elapsed for model construction 150.457 sec\n",
      "\tTime elapsed for prediction 0.901 sec\n",
      "\tTest error: 1263.213\n",
      "\tTrain error: 1253.464\n",
      "MLP:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Notandi\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTime elapsed for model construction 1372.075 sec\n",
      "\tTime elapsed for prediction 6.929 sec\n",
      "\tTest error: 1363.668\n",
      "\tTrain error: 1361.900\n"
     ]
    }
   ],
   "source": [
    "ESTIMATORS = {\n",
    "    # Linear\n",
    "    \"LinearRegression\": LinearRegression(n_jobs=-1),\n",
    "    \"Ridge\": Ridge(),\n",
    "    \"Lasso\": Lasso(),\n",
    "    \"ElasticNet\": ElasticNet(),\n",
    "    # Non-linear\n",
    "    \"BaggingRegressor\": BaggingRegressor(n_jobs=-1),\n",
    "    \"ExtraTreesRegressor\": ExtraTreesRegressor(n_jobs=-1),\n",
    "    \"RandomForestRegressor\": RandomForestRegressor(n_jobs=-1),\n",
    "    \"GradientBoostingRegressor\": GradientBoostingRegressor(loss='huber'),\n",
    "    \"MLP\":  MLPRegressor(hidden_layer_sizes=(150,)),\n",
    "}\n",
    "\n",
    "# Test PCA and NMF\n",
    "data = Data(\"train.csv\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = data.get_split(pca_components=120)\n",
    "print(f'PCA with 120 components')\n",
    "for name, estimator in ESTIMATORS.items():\n",
    "    evaluate(name, estimator, X_train, X_test, y_train, y_test)\n",
    "    \n",
    "X_train, X_test, y_train, y_test = data.get_split(nmf_components=90)\n",
    "print(f'NMF with 90 components')\n",
    "for name, estimator in ESTIMATORS.items():\n",
    "    evaluate(name, estimator, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBR n_estimators=200:\n",
      "\tTime elapsed for model construction 9316.946 sec\n",
      "\tTime elapsed for prediction 4.889 sec\n",
      "\tTest error: 1163.757\n",
      "\tTrain error: 1086.791\n",
      "GBR n_estimators=250:\n",
      "\tTime elapsed for model construction 5754.714 sec\n",
      "\tTime elapsed for prediction 4.712 sec\n",
      "\tTest error: 1162.030\n",
      "\tTrain error: 1076.098\n",
      "GBR n_estimators=300:\n",
      "\tTime elapsed for model construction 6771.478 sec\n",
      "\tTime elapsed for prediction 5.666 sec\n",
      "\tTest error: 1160.265\n",
      "\tTrain error: 1066.413\n",
      "GBR n_estimators=350:\n",
      "\tTime elapsed for model construction 23563.061 sec\n",
      "\tTime elapsed for prediction 7.427 sec\n",
      "\tTest error: 1159.374\n",
      "\tTrain error: 1057.450\n",
      "GBR n_estimators=400:\n",
      "\tTime elapsed for model construction 8711.057 sec\n",
      "\tTime elapsed for prediction 7.002 sec\n",
      "\tTest error: 1158.555\n",
      "\tTrain error: 1052.084\n",
      "GBR n_estimators=450:\n",
      "\tTime elapsed for model construction 9692.810 sec\n",
      "\tTime elapsed for prediction 7.645 sec\n",
      "\tTest error: 1158.072\n",
      "\tTrain error: 1046.006\n",
      "GBR n_estimators=500:\n",
      "\tTime elapsed for model construction 10792.895 sec\n",
      "\tTime elapsed for prediction 8.363 sec\n",
      "\tTest error: 1158.072\n",
      "\tTrain error: 1039.049\n",
      "GBR n_estimators=500:\n"
     ]
    }
   ],
   "source": [
    "data = Data(\"train.csv\")\n",
    "X_train, X_test, y_train, y_test = data.get_split()\n",
    "for n_estimators in np.r_[np.arange(200, 501, 50), np.arange(500, 1001, 100)]:\n",
    "    estimator = GradientBoostingRegressor(loss='huber', alpha=0.5,\n",
    "                                n_estimators=n_estimators, max_depth=6,\n",
    "                                learning_rate=0.1, min_samples_leaf=10,\n",
    "                                min_samples_split=10)\n",
    "    evaluate(f'GBR n_estimators={n_estimators}', estimator, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBR n_estimators=600:\n"
     ]
    }
   ],
   "source": [
    "data = Data(\"train.csv\")\n",
    "X_train, X_test, y_train, y_test = data.get_split()\n",
    "for n_estimators in np.arange(600, 1001, 100):\n",
    "    estimator = GradientBoostingRegressor(loss='huber', alpha=0.5,\n",
    "                                n_estimators=n_estimators, max_depth=6,\n",
    "                                learning_rate=0.1, min_samples_leaf=10,\n",
    "                                min_samples_split=10)\n",
    "    evaluate(f'GBR n_estimators={n_estimators}', estimator, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####################################################\n",
    "# Stuff below this line should probably be deleted #\n",
    "####################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 188318 entries, 1 to 587633\n",
      "Columns: 1037 entries, cont1 to cat116_Y\n",
      "dtypes: float64(14), uint8(1023)\n",
      "memory usage: 205.3 MB\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 125546 entries, 4 to 587634\n",
      "Columns: 1037 entries, cont1 to cat113_T\n",
      "dtypes: float64(14), int64(74), uint8(949)\n",
      "memory usage: 198.9 MB\n"
     ]
    }
   ],
   "source": [
    "# Reading in the final test data\n",
    "data = Data(\"train.csv\")\n",
    "X_train, y_train = data.df_X, data.df_y\n",
    "X_test = data.read_test_data(\"test.csv\")\n",
    "X_test = data.df_X_test\n",
    "\n",
    "X_train.info()\n",
    "print()\n",
    "X_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR with PCA:2:\n",
      "\tTime elapsed for model construction 0.031 sec\n",
      "\tTime elapsed for prediction 0.000 sec\n",
      "\tTest error: 1683.717\n",
      "\tTrain error: 1700.964\n",
      "LR with PCA:5:\n",
      "\tTime elapsed for model construction 0.031 sec\n",
      "\tTime elapsed for prediction 0.016 sec\n",
      "\tTest error: 1654.642\n",
      "\tTrain error: 1658.467\n",
      "LR with PCA:10:\n",
      "\tTime elapsed for model construction 0.112 sec\n",
      "\tTime elapsed for prediction 0.012 sec\n",
      "\tTest error: 1484.401\n",
      "\tTrain error: 1477.059\n",
      "LR with PCA:20:\n",
      "\tTime elapsed for model construction 0.156 sec\n",
      "\tTime elapsed for prediction 0.016 sec\n",
      "\tTest error: 1473.703\n",
      "\tTrain error: 1457.921\n",
      "LR with PCA:30:\n",
      "\tTime elapsed for model construction 0.248 sec\n",
      "\tTime elapsed for prediction 0.016 sec\n",
      "\tTest error: 1447.598\n",
      "\tTrain error: 1438.666\n",
      "LR with PCA:40:\n",
      "\tTime elapsed for model construction 0.404 sec\n",
      "\tTime elapsed for prediction 0.024 sec\n",
      "\tTest error: 1426.002\n",
      "\tTrain error: 1422.197\n",
      "LR with PCA:50:\n",
      "\tTime elapsed for model construction 0.476 sec\n",
      "\tTime elapsed for prediction 0.028 sec\n",
      "\tTest error: 1409.730\n",
      "\tTrain error: 1401.223\n",
      "LR with PCA:60:\n",
      "\tTime elapsed for model construction 0.572 sec\n",
      "\tTime elapsed for prediction 0.032 sec\n",
      "\tTest error: 1381.847\n",
      "\tTrain error: 1379.167\n",
      "LR with PCA:70:\n",
      "\tTime elapsed for model construction 0.744 sec\n",
      "\tTime elapsed for prediction 0.040 sec\n",
      "\tTest error: 1386.563\n",
      "\tTrain error: 1372.603\n",
      "LR with PCA:80:\n",
      "\tTime elapsed for model construction 1.084 sec\n",
      "\tTime elapsed for prediction 0.044 sec\n",
      "\tTest error: 1357.678\n",
      "\tTrain error: 1365.025\n",
      "LR with PCA:90:\n",
      "\tTime elapsed for model construction 1.096 sec\n",
      "\tTime elapsed for prediction 0.060 sec\n",
      "\tTest error: 1350.919\n",
      "\tTrain error: 1341.440\n",
      "LR with PCA:100:\n",
      "\tTime elapsed for model construction 1.328 sec\n",
      "\tTime elapsed for prediction 0.056 sec\n",
      "\tTest error: 1354.997\n",
      "\tTrain error: 1326.533\n",
      "LR with PCA:110:\n",
      "\tTime elapsed for model construction 1.352 sec\n",
      "\tTime elapsed for prediction 0.068 sec\n",
      "\tTest error: 1336.755\n",
      "\tTrain error: 1328.156\n",
      "LR with PCA:120:\n",
      "\tTime elapsed for model construction 1.724 sec\n",
      "\tTime elapsed for prediction 0.088 sec\n",
      "\tTest error: 1331.710\n",
      "\tTrain error: 1329.179\n",
      "LR with PCA:130:\n",
      "\tTime elapsed for model construction 1.820 sec\n",
      "\tTime elapsed for prediction 0.068 sec\n",
      "\tTest error: 1332.694\n",
      "\tTrain error: 1325.105\n",
      "LR with PCA:140:\n",
      "\tTime elapsed for model construction 1.908 sec\n",
      "\tTime elapsed for prediction 0.088 sec\n",
      "\tTest error: 1333.099\n",
      "\tTrain error: 1322.293\n",
      "LR with PCA:150:\n",
      "\tTime elapsed for model construction 2.684 sec\n",
      "\tTime elapsed for prediction 0.108 sec\n",
      "\tTest error: 1319.059\n",
      "\tTrain error: 1325.220\n",
      "LR with PCA:160:\n",
      "\tTime elapsed for model construction 2.244 sec\n",
      "\tTime elapsed for prediction 0.096 sec\n",
      "\tTest error: 1334.407\n",
      "\tTrain error: 1318.496\n",
      "LR with PCA:170:\n",
      "\tTime elapsed for model construction 2.784 sec\n",
      "\tTime elapsed for prediction 0.124 sec\n",
      "\tTest error: 1321.079\n",
      "\tTrain error: 1324.227\n",
      "LR with PCA:180:\n",
      "\tTime elapsed for model construction 2.828 sec\n",
      "\tTime elapsed for prediction 0.104 sec\n",
      "\tTest error: 1335.963\n",
      "\tTrain error: 1315.966\n",
      "LR with PCA:190:\n",
      "\tTime elapsed for model construction 3.052 sec\n",
      "\tTime elapsed for prediction 0.100 sec\n",
      "\tTest error: 1324.000\n",
      "\tTrain error: 1317.470\n",
      "LR with PCA:200:\n",
      "\tTime elapsed for model construction 3.324 sec\n",
      "\tTime elapsed for prediction 0.104 sec\n",
      "\tTest error: 1318.532\n",
      "\tTrain error: 1318.924\n",
      "LR with PCA:210:\n",
      "\tTime elapsed for model construction 3.579 sec\n",
      "\tTime elapsed for prediction 0.125 sec\n",
      "\tTest error: 1312.776\n",
      "\tTrain error: 1321.388\n",
      "LR with PCA:220:\n",
      "\tTime elapsed for model construction 3.728 sec\n",
      "\tTime elapsed for prediction 0.140 sec\n",
      "\tTest error: 1318.574\n",
      "\tTrain error: 1315.327\n",
      "LR with PCA:230:\n",
      "\tTime elapsed for model construction 4.057 sec\n",
      "\tTime elapsed for prediction 0.156 sec\n",
      "\tTest error: 1314.989\n",
      "\tTrain error: 1318.100\n",
      "LR with PCA:240:\n",
      "\tTime elapsed for model construction 4.028 sec\n",
      "\tTime elapsed for prediction 0.133 sec\n",
      "\tTest error: 1324.426\n",
      "\tTrain error: 1314.441\n"
     ]
    }
   ],
   "source": [
    "data = Data(\"train.csv\")\n",
    "for n_comp in np.r_[2, 5, np.arange(10, 250, 10)]:\n",
    "    X_train, X_test, y_train, y_test = data.get_split(pca_components=n_comp)\n",
    "    evaluate(f'LR with PCA:{n_comp}', LinearRegression(n_jobs=-1), X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR with NMF:2:\n",
      "\tTime elapsed for model construction 0.031 sec\n",
      "\tTime elapsed for prediction 0.016 sec\n",
      "\tTest error: 1972.926\n",
      "\tTrain error: 1958.380\n",
      "LR with NMF:5:\n",
      "\tTime elapsed for model construction 0.047 sec\n",
      "\tTime elapsed for prediction 0.000 sec\n",
      "\tTest error: 1660.442\n",
      "\tTrain error: 1665.419\n",
      "LR with NMF:10:\n",
      "\tTime elapsed for model construction 0.078 sec\n",
      "\tTime elapsed for prediction 0.016 sec\n",
      "\tTest error: 1637.501\n",
      "\tTrain error: 1626.085\n",
      "LR with NMF:20:\n",
      "\tTime elapsed for model construction 0.156 sec\n",
      "\tTime elapsed for prediction 0.016 sec\n",
      "\tTest error: 1472.832\n",
      "\tTrain error: 1463.270\n",
      "LR with NMF:30:\n",
      "\tTime elapsed for model construction 0.247 sec\n",
      "\tTime elapsed for prediction 0.020 sec\n",
      "\tTest error: 1424.869\n",
      "\tTrain error: 1425.406\n",
      "LR with NMF:40:\n",
      "\tTime elapsed for model construction 0.330 sec\n",
      "\tTime elapsed for prediction 0.026 sec\n",
      "\tTest error: 1408.313\n",
      "\tTrain error: 1418.324\n",
      "LR with NMF:50:\n",
      "\tTime elapsed for model construction 0.431 sec\n",
      "\tTime elapsed for prediction 0.016 sec\n",
      "\tTest error: 1407.752\n",
      "\tTrain error: 1415.506\n",
      "LR with NMF:60:\n",
      "\tTime elapsed for model construction 0.528 sec\n",
      "\tTime elapsed for prediction 0.031 sec\n",
      "\tTest error: 1391.779\n",
      "\tTrain error: 1390.387\n",
      "LR with NMF:70:\n",
      "\tTime elapsed for model construction 0.621 sec\n",
      "\tTime elapsed for prediction 0.041 sec\n",
      "\tTest error: 1379.093\n",
      "\tTrain error: 1376.153\n",
      "LR with NMF:80:\n",
      "\tTime elapsed for model construction 0.789 sec\n",
      "\tTime elapsed for prediction 0.026 sec\n",
      "\tTest error: 1375.915\n",
      "\tTrain error: 1383.899\n",
      "LR with NMF:90:\n",
      "\tTime elapsed for model construction 1.013 sec\n",
      "\tTime elapsed for prediction 0.047 sec\n",
      "\tTest error: 1336.926\n",
      "\tTrain error: 1345.421\n",
      "LR with NMF:100:\n",
      "\tTime elapsed for model construction 0.957 sec\n",
      "\tTime elapsed for prediction 0.047 sec\n",
      "\tTest error: 1338.928\n",
      "\tTrain error: 1341.378\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-73-6f0340f2c62d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mData\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"train.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mn_comp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mr_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m250\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnmf_components\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_comp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'LR with NMF:{n_comp}'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-71-238a779626bd>\u001b[0m in \u001b[0;36mget_split\u001b[1;34m(self, test_size, pca_components, nmf_components)\u001b[0m\n\u001b[0;32m     52\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mnmf_components\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m             \u001b[0mnmf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNMF\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnmf_components\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m             \u001b[0mX_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnmf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m             \u001b[0mX_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnmf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m         \u001b[1;32mreturn\u001b[0m  \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Notandi\\Anaconda3\\lib\\site-packages\\sklearn\\decomposition\\nmf.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y, W, H)\u001b[0m\n\u001b[0;32m   1233\u001b[0m             \u001b[0ml1_ratio\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ml1_ratio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mregularization\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'both'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1234\u001b[0m             \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1235\u001b[1;33m             shuffle=self.shuffle)\n\u001b[0m\u001b[0;32m   1236\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1237\u001b[0m         self.reconstruction_err_ = _beta_divergence(X, W, H, self.beta_loss,\n",
      "\u001b[1;32mC:\\Users\\Notandi\\Anaconda3\\lib\\site-packages\\sklearn\\decomposition\\nmf.py\u001b[0m in \u001b[0;36mnon_negative_factorization\u001b[1;34m(X, W, H, n_components, init, update_H, solver, beta_loss, tol, max_iter, alpha, l1_ratio, regularization, random_state, verbose, shuffle)\u001b[0m\n\u001b[0;32m   1021\u001b[0m                                                \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1022\u001b[0m                                                \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1023\u001b[1;33m                                                random_state=random_state)\n\u001b[0m\u001b[0;32m   1024\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0msolver\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'mu'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1025\u001b[0m         W, H, n_iter = _fit_multiplicative_update(X, W, H, beta_loss, max_iter,\n",
      "\u001b[1;32mC:\\Users\\Notandi\\Anaconda3\\lib\\site-packages\\sklearn\\decomposition\\nmf.py\u001b[0m in \u001b[0;36m_fit_coordinate_descent\u001b[1;34m(X, W, H, tol, max_iter, l1_reg_W, l1_reg_H, l2_reg_W, l2_reg_H, update_H, verbose, shuffle, random_state)\u001b[0m\n\u001b[0;32m    483\u001b[0m         \u001b[1;31m# Update W\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    484\u001b[0m         violation += _update_coordinate_descent(X, W, Ht, l1_reg_W,\n\u001b[1;32m--> 485\u001b[1;33m                                                 l2_reg_W, shuffle, rng)\n\u001b[0m\u001b[0;32m    486\u001b[0m         \u001b[1;31m# Update H\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    487\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mupdate_H\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Notandi\\Anaconda3\\lib\\site-packages\\sklearn\\decomposition\\nmf.py\u001b[0m in \u001b[0;36m_update_coordinate_descent\u001b[1;34m(X, W, Ht, l1_reg, l2_reg, shuffle, random_state)\u001b[0m\n\u001b[0;32m    397\u001b[0m     \u001b[1;31m# The following seems to be required on 64-bit Windows w/ Python 3.5.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    398\u001b[0m     \u001b[0mpermutation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpermutation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 399\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_update_cdnmf_fast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mHHt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mXHt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpermutation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    400\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    401\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data = Data(\"train.csv\")\n",
    "for n_comp in np.r_[2, 5, np.arange(10, 250, 10)]:\n",
    "    X_train, X_test, y_train, y_test = data.get_split(nmf_components=n_comp)\n",
    "    evaluate(f'LR with NMF:{n_comp}', LinearRegression(n_jobs=-1), X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = Data(\"train.csv\")\n",
    "for n_comp in np.r_[2, 5, np.arange(10, 250, 10)]:\n",
    "    X_train, X_test, y_train, y_test = data.get_split(nmf_components=n_comp)\n",
    "    evaluate(f'LR with NMF:{n_comp}', LinearRegression(n_jobs=-1), X_train, X_test, y_train, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
